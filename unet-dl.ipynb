{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":30892,"databundleVersionId":2715462,"sourceType":"competition"},{"sourceId":6974612,"sourceType":"datasetVersion","datasetId":4007626}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torchmetrics\n!pip install timm","metadata":{"execution":{"iopub.status.busy":"2023-11-17T09:47:00.780679Z","iopub.execute_input":"2023-11-17T09:47:00.781607Z","iopub.status.idle":"2023-11-17T09:47:26.913021Z","shell.execute_reply.started":"2023-11-17T09:47:00.781572Z","shell.execute_reply":"2023-11-17T09:47:26.912085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport cv2\nfrom torchvision.io import read_image\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, random_split, DataLoader\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nfrom torchvision.transforms import ToTensor\nfrom PIL import Image\nimport os\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision \nfrom torchvision import transforms\nfrom torchinfo import summary\nimport timm\nimport torchmetrics\nfrom tqdm import tqdm\nimport wandb","metadata":{"execution":{"iopub.status.busy":"2023-11-17T11:27:24.280548Z","iopub.execute_input":"2023-11-17T11:27:24.280833Z","iopub.status.idle":"2023-11-17T11:27:39.958736Z","shell.execute_reply.started":"2023-11-17T11:27:24.280808Z","shell.execute_reply":"2023-11-17T11:27:39.957950Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Hyperparameter: \nbatch_size = 8 # batch_size \n\nepochs = 70 # number of epochs \n\ntrain_size = 0.9 \n\nlearning_rate = 0.0001 # learning_rate\n","metadata":{"execution":{"iopub.status.busy":"2023-11-17T09:47:41.606505Z","iopub.execute_input":"2023-11-17T09:47:41.607131Z","iopub.status.idle":"2023-11-17T09:47:41.611988Z","shell.execute_reply.started":"2023-11-17T09:47:41.607097Z","shell.execute_reply":"2023-11-17T09:47:41.611092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#1 Prepare data \\\nThis part I reference many source code from the \"code\" part in the competition website \n","metadata":{}},{"cell_type":"code","source":"### This part I reference source code from the \"code\" part in the competition website \nclass CustomImageDataset(Dataset):\n    def __init__(self, images_path, masks_path, resize=None):\n        self.img_dir = images_path\n        self.label_dir = masks_path\n        self.resize = resize\n        images_list = os.listdir(images_path)\n        masks_list = os.listdir(masks_path)\n        \n        self.images_list = [images_path +\"/\"+ image_name for image_name in images_list]\n        self.masks_list = [masks_path +\"/\" +  mask_name for mask_name in masks_list]\n\n    def __len__(self):\n        return len(self.images)\n    \n    def read_mask(self, mask_path):\n        image = cv2.imread(mask_path)\n        image = cv2.resize(image, self.resize)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n        \n        \n        # Create red_mask for ground_truth image\n        lower1 = np.array([0, 100, 20])\n        upper1 = np.array([10, 255, 255])\n\n        lower2 = np.array([160,100,20])\n        upper2 = np.array([179,255,255])\n        lower_mask = cv2.inRange(image, lower1, upper1)\n        upper_mask = cv2.inRange(image, lower2, upper2)\n        \n        red_mask = lower_mask + upper_mask\n        red_mask[red_mask != 0] = 1\n        \n        # Create green_mask for ground_truth image\n        green_mask = cv2.inRange(image, (36, 25, 25), (70, 255, 255))\n        green_mask[green_mask != 0] = 2\n        \n        \n        full_mask = cv2.bitwise_or(red_mask, green_mask)\n        full_mask = np.expand_dims(full_mask, axis=-1) \n        full_mask = full_mask.astype(np.uint8)\n        \n        return full_mask\n\n    def __getitem__(self, idx):\n        img_path = self.images_list[idx]\n        label_path = self.masks_list[idx]\n        image = cv2.imread(img_path)  # Đọc ảnh dưới dạng BGR\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # Convert sang RGB\n        label = self.read_mask(label_path)  \n        image = cv2.resize(image, self.resize)\n            \n        return image, label\n\n    def show_image(self, idx):\n        img_path = self.images_list[idx]\n        label_path = self.masks_list[idx]\n        image = plt.imread(img_path)\n        label = plt.imread(label_path)\n        fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n        axs[0].imshow(image)\n        axs[0].set_title('Image')\n        axs[1].imshow(label)\n        axs[1].set_title('Label')\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-17T09:47:41.614949Z","iopub.execute_input":"2023-11-17T09:47:41.615317Z","iopub.status.idle":"2023-11-17T09:47:41.630862Z","shell.execute_reply.started":"2023-11-17T09:47:41.615283Z","shell.execute_reply":"2023-11-17T09:47:41.629905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_DIR = '/kaggle/input/bkai-igh-neopolyp/train/train'\nTRAIN_MASK_DIR = '/kaggle/input/bkai-igh-neopolyp/train_gt/train_gt'\n","metadata":{"execution":{"iopub.status.busy":"2023-11-17T09:47:41.631945Z","iopub.execute_input":"2023-11-17T09:47:41.632280Z","iopub.status.idle":"2023-11-17T09:47:41.649887Z","shell.execute_reply.started":"2023-11-17T09:47:41.632247Z","shell.execute_reply":"2023-11-17T09:47:41.649191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = CustomImageDataset(images_path= TRAIN_DIR,\n                             masks_path= TRAIN_MASK_DIR,\n                             resize= (256,256))","metadata":{"execution":{"iopub.status.busy":"2023-11-17T09:47:41.650806Z","iopub.execute_input":"2023-11-17T09:47:41.651051Z","iopub.status.idle":"2023-11-17T09:47:41.799822Z","shell.execute_reply.started":"2023-11-17T09:47:41.651028Z","shell.execute_reply":"2023-11-17T09:47:41.799049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the datasets into image data list and label data image, to be convinient to split the training data and valid data later \nimages_data = []\nlabels_data = []\nfor x,y in dataset:\n    images_data.append(x)\n    labels_data.append(y)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T09:47:41.800973Z","iopub.execute_input":"2023-11-17T09:47:41.801348Z","iopub.status.idle":"2023-11-17T09:48:30.973175Z","shell.execute_reply.started":"2023-11-17T09:47:41.801312Z","shell.execute_reply":"2023-11-17T09:48:30.972253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(CustomImageDataset):\n    def __init__(self, data, targets, transform=None):\n        self.data = data\n        self.targets = targets\n        self.transform = transform\n\n    def __getitem__(self, index):\n        image = self.data[index]\n        label = self.targets[index]\n        if self.transform:\n            transformed = self.transform(image=image, mask=label)\n            image = transformed['image'].float()\n            label = transformed['mask'].float()\n            label = label.permute(2, 0, 1)\n        return image, label\n    \n    def __len__(self):\n        return len(self.data)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-17T09:48:30.974590Z","iopub.execute_input":"2023-11-17T09:48:30.974973Z","iopub.status.idle":"2023-11-17T09:48:30.982515Z","shell.execute_reply.started":"2023-11-17T09:48:30.974936Z","shell.execute_reply":"2023-11-17T09:48:30.981654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### This part I also reference source code from the \"code\" part in the competition website \ntrain_transform = A.Compose([\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    A.RandomGamma (gamma_limit=(70, 130), eps=None, always_apply=False, p=0.2),\n    A.RGBShift(p=0.3, r_shift_limit=10, g_shift_limit=10, b_shift_limit=10),\n    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n    ToTensorV2(),\n])\n\nval_transform = A.Compose([\n    A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n    ToTensorV2(),\n])\n\n\ntrain_size = int(train_size * len(images_data))\nval_size = len(images_data) - train_size\ntrain_dataset = CustomDataset(images_data[:train_size], labels_data[:train_size], transform=train_transform)\nval_dataset = CustomDataset(images_data[train_size:], labels_data[train_size:], transform=val_transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nvalid_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T09:48:30.983810Z","iopub.execute_input":"2023-11-17T09:48:30.984162Z","iopub.status.idle":"2023-11-17T09:48:30.997379Z","shell.execute_reply.started":"2023-11-17T09:48:30.984127Z","shell.execute_reply":"2023-11-17T09:48:30.996643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#2 Build the model: \\\nI build the UNet Model with the backbone of encoder is **\"resnet101\" **\n\nI Use the module **timm** to import backbone **\"resnet101\"** and put in into UNet model","metadata":{}},{"cell_type":"code","source":"class decoder_block(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(decoder_block, self).__init__()\n        \n        \n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding='same')\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding='same')\n        \n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        \n        self.relu = nn.ReLU() \n        self.dropout = nn.Dropout(p=0.3)\n    \n    def forward(self, x, skip_layer):\n        x = torch.cat([x, skip_layer], axis=1)\n        \n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        \n        x = self.dropout(x)\n        \n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.relu(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2023-11-17T09:48:31.000934Z","iopub.execute_input":"2023-11-17T09:48:31.001413Z","iopub.status.idle":"2023-11-17T09:48:31.021786Z","shell.execute_reply.started":"2023-11-17T09:48:31.001386Z","shell.execute_reply":"2023-11-17T09:48:31.021112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class bottleneck_block(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(bottleneck_block, self).__init__()\n        \n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding='same')\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding='same')\n        \n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        \n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(p=0.3)\n        \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        \n        x = self.dropout(x)\n        \n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.relu(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2023-11-17T09:48:31.022838Z","iopub.execute_input":"2023-11-17T09:48:31.023159Z","iopub.status.idle":"2023-11-17T09:48:31.036839Z","shell.execute_reply.started":"2023-11-17T09:48:31.023127Z","shell.execute_reply":"2023-11-17T09:48:31.036133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# UNet model\nclass UNet(nn.Module):\n    def __init__(self, n_class=3):\n        super(UNet, self).__init__()\n#         # Encoder blocks\n\n        ## backbone:\n        self.backbone = timm.create_model(\"resnet101\", pretrained = True, features_only = True)\n        \n        \n        # Bottleneck block\n        self.bottleneck = bottleneck_block(2048, 1024)\n        \n        # Decoder blocks\n        self.dec1 = decoder_block(1024+1024, 512)\n        self.dec2 = decoder_block(512+512, 256)\n        self.dec3 = decoder_block(256+256, 128)\n        self.dec4 = decoder_block(128+64, 64)\n        \n        #upsampling\n        self.transpose_conv1 = nn.ConvTranspose2d(1024,1024, kernel_size=2, stride=2)\n        self.transpose_conv2 = nn.ConvTranspose2d(512,512, kernel_size=2, stride=2)\n        self.transpose_conv3 = nn.ConvTranspose2d(256,256, kernel_size=2, stride=2)\n        self.transpose_conv4 = nn.ConvTranspose2d(128,128, kernel_size=2, stride=2)\n        self.transpose_conv5 = nn.ConvTranspose2d(n_class,n_class, kernel_size=2, stride=2)\n\n\n\n        \n        # 1x1 convolution\n        self.out = nn.Conv2d(64, n_class, kernel_size=1, padding='same')\n        \n    def forward(self, image):\n        n1,n2,n3,n4,n5 = self.backbone(image)\n        \n        n6 = self.bottleneck(n5)\n        \n        n7 = self.dec1(self.transpose_conv1(n6), n4)\n        n8 = self.dec2(self.transpose_conv2(n7), n3)\n        n9 = self.dec3(self.transpose_conv3(n8), n2)\n        n10 = self.dec4(self.transpose_conv4(n9), n1)\n        \n        \n        output = self.out(n10)\n        \n        \n        return self.transpose_conv5(output)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T09:48:31.037882Z","iopub.execute_input":"2023-11-17T09:48:31.038649Z","iopub.status.idle":"2023-11-17T09:48:31.055488Z","shell.execute_reply.started":"2023-11-17T09:48:31.038617Z","shell.execute_reply":"2023-11-17T09:48:31.054566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image,label = train_dataset[2]\n\nlabel_array = label.permute(1, 2, 0).numpy()\nimage_array = image.permute(1, 2, 0).numpy()\n\nfig, axs = plt.subplots(1, 2, figsize=(10, 5))\n\naxs[0].imshow(image_array)\naxs[0].set_title('Image')\naxs[0].axis('off')  \naxs[1].imshow(label_array)\naxs[1].set_title('Label')\naxs[1].axis('off')  \n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-17T09:48:31.056499Z","iopub.execute_input":"2023-11-17T09:48:31.056738Z","iopub.status.idle":"2023-11-17T09:48:31.484236Z","shell.execute_reply.started":"2023-11-17T09:48:31.056716Z","shell.execute_reply":"2023-11-17T09:48:31.483342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"color_dict= {0: (0, 0, 0),\n             1: (255, 0, 0),\n             2: (0, 255, 0)}\ndef mask_to_rgb(mask, color_dict):\n    output = np.zeros((mask.shape[0], mask.shape[1], 3))\n\n    for k in color_dict.keys():\n        output[mask==k] = color_dict[k]\n\n    return np.uint8(output)    ","metadata":{"execution":{"iopub.status.busy":"2023-11-17T09:48:31.485406Z","iopub.execute_input":"2023-11-17T09:48:31.485717Z","iopub.status.idle":"2023-11-17T09:48:31.491803Z","shell.execute_reply.started":"2023-11-17T09:48:31.485690Z","shell.execute_reply":"2023-11-17T09:48:31.490761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# wandb.init(\n#     project = 'Unet_polyp-Segmentation'\n# )","metadata":{"execution":{"iopub.status.busy":"2023-11-17T09:48:31.492710Z","iopub.execute_input":"2023-11-17T09:48:31.492965Z","iopub.status.idle":"2023-11-17T09:48:31.509397Z","shell.execute_reply.started":"2023-11-17T09:48:31.492941Z","shell.execute_reply":"2023-11-17T09:48:31.508638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train function for each epoch\ndef train(train_dataloader, valid_dataloader,optimizer, epoch):\n    print(f\"Start epoch #{epoch+1}, learning rate for this epoch: {optimizer.param_groups[0]['lr']}\")\n    train_loss_epoch = 0\n    test_loss_epoch = 0\n    last_loss = 999999999\n    model.train()\n    for i, (data,targets) in enumerate(tqdm(train_dataloader), start = 1):\n        n = data.shape[0]\n        \n        # Load data into GPU\n        data, targets = data.to(device), targets.to(device)\n        \n        targets  = targets.squeeze(dim = 1).long()\n\n        optimizer.zero_grad()\n        outputs = model(data)\n\n                \n\n        # Backpropagation, compute gradients\n        loss = loss_function(outputs, targets.long())\n        loss.backward()\n\n        # Apply gradients\n        optimizer.step()\n        \n        # Save loss\n        \n        with torch.no_grad():\n            mask = outputs.argmax(dim = 1).squeeze(1)\n            train_loss_epoch += loss.item()\n            \n            # dice Score:\n            dice_score = dice_fn(mask, targets.long())\n            \n            # iou_score:\n            iou_score = iou_fn(mask, targets.long())\n            \n            train_loss_meter.update(loss.item(), n)\n            iou_meter.update(iou_score,n)\n            dice_meter.update(dice_score, n)\n            \n            \n    print(\"Epoch: {}, train_loss: {}, IoU: {}, dice_score: {}\".format(\n            epoch, train_loss_meter.avg,iou_meter.avg, dice_meter.avg\n        ))\n           \n                \n    train_loss_epoch/= (i + 1)\n    \n    # Evaluate the validation set\n    model.eval()\n#     count = 0\n    with torch.no_grad():\n        for data, targets in valid_dataloader:\n            data, targets = data.to(device), targets.to(device)\n            test_output = model(data)\n            targets  = targets.squeeze(dim = 1).long()\n\n            test_loss = loss_function(test_output, targets.long())\n            test_loss_epoch += test_loss.item()\n            \n#             if count == len(valid_dataloader):\n#                 label = targets[0].cpu().numpy()\n#                 label = mask_to_rgb(label,color_dict)\n#                 outputs[0] = test_output[0].softmax(dim=0)\n#                 output = outputs[0].cpu().numpy()\n#                 output = np.argmax(output, axis=0)\n#                 output = mask_to_rgb(output,color_dict)\n#                 fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n#                 axs[0].imshow(label)\n#                 axs[0].set_title('Label')\n#                 axs[1].imshow(output)\n#                 axs[1].set_title('Output')\n#                 plt.show()\n            \n    test_loss_epoch/= (i+1)\n    \n    return train_loss_epoch , test_loss_epoch","metadata":{"execution":{"iopub.status.busy":"2023-11-17T09:49:43.858332Z","iopub.execute_input":"2023-11-17T09:49:43.859107Z","iopub.status.idle":"2023-11-17T09:49:43.871534Z","shell.execute_reply.started":"2023-11-17T09:49:43.859075Z","shell.execute_reply":"2023-11-17T09:49:43.870564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AverageMeter(object):\n    def __init__(self):\n        self.reset()\n        \n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n        \n    def update(self, val, n=1):\n        self.val = val\n        self.sum += self.val *n \n        self.count += n\n        self.avg = self.sum/self.count","metadata":{"execution":{"iopub.status.busy":"2023-11-17T09:48:31.524650Z","iopub.execute_input":"2023-11-17T09:48:31.524911Z","iopub.status.idle":"2023-11-17T09:48:31.541135Z","shell.execute_reply.started":"2023-11-17T09:48:31.524887Z","shell.execute_reply":"2023-11-17T09:48:31.540408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_model(model, optimizer, path):\n    checkpoint = {\n        \"model\": model.state_dict(),\n        \"optimizer\": optimizer.state_dict(),\n    }\n    torch.save(checkpoint, path)\n\ndef load_model(model, optimizer, path):\n    checkpoint = torch.load(path)\n    model.load_state_dict(checkpoint[\"model\"])\n    optimizer.load_state_dict(checkpoint['optimizer'])\n    return model, optimizer","metadata":{"execution":{"iopub.status.busy":"2023-11-17T09:48:31.542078Z","iopub.execute_input":"2023-11-17T09:48:31.542349Z","iopub.status.idle":"2023-11-17T09:48:31.552801Z","shell.execute_reply.started":"2023-11-17T09:48:31.542326Z","shell.execute_reply":"2023-11-17T09:48:31.552052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n# Sepecify model :\nmodel = UNet()\nmodel.to(device)\n\n#Define loss funciton \nloss_function = nn.CrossEntropyLoss()\n\n# Define the optimizer (Adam optimizer)\noptimizer = optim.Adam(params=model.parameters(), lr=learning_rate)\n#optimizer.load_state_dict(checkpoint['optimizer'])\n\n\n#metrics: \ndice_fn = torchmetrics.Dice(num_classes = 3, average = \"macro\").to(device)\n\niou_fn = torchmetrics.JaccardIndex(num_classes = 3, task = \"multiclass\", average = \"macro\").to(device)\n\n#meter:\nloss_meter = AverageMeter()\ndice_meter = AverageMeter()\niou_meter = AverageMeter()\ntrain_loss_meter = AverageMeter()","metadata":{"execution":{"iopub.status.busy":"2023-11-17T09:48:31.553855Z","iopub.execute_input":"2023-11-17T09:48:31.554428Z","iopub.status.idle":"2023-11-17T09:48:42.838866Z","shell.execute_reply.started":"2023-11-17T09:48:31.554396Z","shell.execute_reply":"2023-11-17T09:48:42.838098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_path = checkpoint_path = '/kaggle/working/unet_model.pth'\nsave_model(model, optimizer, checkpoint_path)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T09:48:42.839949Z","iopub.execute_input":"2023-11-17T09:48:42.840284Z","iopub.status.idle":"2023-11-17T09:48:43.501219Z","shell.execute_reply.started":"2023-11-17T09:48:42.840256Z","shell.execute_reply":"2023-11-17T09:48:43.500448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.login(\n#     set the wandb project where this run will be logged\n#     project= \"PolypSegment\", \n    key = \"5b871d83e15f995c416a95e926f3841ca478ed62\",\n)\nwandb.init(\n    project = \"PolypSegment1\"\n)\n#Training loop\ntrain_loss_array = []\ntest_loss_array = []\nlast_loss = 9999999999999\nfor epoch in range(epochs):\n    \n    loss_meter.reset()\n    dice_meter.reset()\n    iou_meter.reset()\n    \n    train_loss_epoch = 0\n    test_loss_epoch = 0\n    (train_loss_epoch, test_loss_epoch) = train(train_loader, \n                                              valid_loader, \n                                              optimizer, epoch)\n    \n    if test_loss_epoch < last_loss:\n        save_model(model, optimizer, checkpoint_path)\n        last_loss = test_loss_epoch\n        \n    #learing_rate_scheduler.step()\n    train_loss_array.append(train_loss_epoch)\n    test_loss_array.append(test_loss_epoch)\n    wandb.log({\"Train loss\": train_loss_epoch, \"Valid loss\": test_loss_epoch})\n    print(\"Epoch {}: loss: {:.4f}\".format(epoch + 1, \n                                        train_loss_array[-1]))\n\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model, optimizer = load_model(model, optimizer, \"/kaggle/working/unet_model.pth\")\ndevice = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir prediction","metadata":{"execution":{"iopub.status.busy":"2023-11-17T09:51:38.562800Z","iopub.execute_input":"2023-11-17T09:51:38.563793Z","iopub.status.idle":"2023-11-17T09:51:39.580406Z","shell.execute_reply.started":"2023-11-17T09:51:38.563756Z","shell.execute_reply":"2023-11-17T09:51:39.579250Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainsize = 256\nmodel.eval()\nfor i in os.listdir(\"/kaggle/input/bkai-igh-neopolyp/test/test\"):\n    img_path = os.path.join(\"/kaggle/input/bkai-igh-neopolyp/test/test\", i)\n    ori_img = cv2.imread(img_path)\n    ori_img = cv2.cvtColor(ori_img, cv2.COLOR_BGR2RGB)\n    ori_w = ori_img.shape[0]\n    ori_h = ori_img.shape[1]\n    img = cv2.resize(ori_img, (trainsize, trainsize))\n    transformed = val_transform(image=img)\n    input_img = transformed[\"image\"]\n    input_img = input_img.unsqueeze(0).to(device)\n    with torch.no_grad():\n        output_mask = model.forward(input_img).squeeze(0).cpu().numpy().transpose(1,2,0)\n    mask = cv2.resize(output_mask, (ori_h, ori_w))\n    mask = np.argmax(mask, axis=2)\n    mask_rgb = mask_to_rgb(mask, color_dict)\n    mask_rgb = cv2.cvtColor(mask_rgb, cv2.COLOR_RGB2BGR)\n    cv2.imwrite(\"prediction/{}\".format(i), mask_rgb) ","metadata":{"execution":{"iopub.status.busy":"2023-11-17T09:50:56.731979Z","iopub.execute_input":"2023-11-17T09:50:56.733136Z","iopub.status.idle":"2023-11-17T09:51:26.657252Z","shell.execute_reply.started":"2023-11-17T09:50:56.733095Z","shell.execute_reply":"2023-11-17T09:51:26.656197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport cv2\nimport os\n\ndef rle_to_string(runs):\n    return ' '.join(str(x) for x in runs)\n\ndef rle_encode_one_mask(mask):\n    pixels = mask.flatten()\n    pixels[pixels > 225] = 255\n    pixels[pixels <= 225] = 0\n    use_padding = False\n    if pixels[0] or pixels[-1]:\n        use_padding = True\n        pixel_padded = np.zeros([len(pixels) + 2], dtype=pixels.dtype)\n        pixel_padded[1:-1] = pixels\n        pixels = pixel_padded\n    rle = np.where(pixels[1:] != pixels[:-1])[0] + 2\n    if use_padding:\n        rle = rle - 1\n    rle[1::2] = rle[1::2] - rle[:-1:2]\n    \n    return rle_to_string(rle)\n\ndef rle2mask(mask_rle, shape=(3,3)):\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T\n\ndef mask2string(dir):\n    strings = []\n    ids = []\n    ws, hs = [[] for i in range(2)]\n    for image_id in os.listdir(dir):\n        id = image_id.split('.')[0]\n        path = os.path.join(dir, image_id)\n        print(path)\n        img = cv2.imread(path)[:,:,::-1]\n        h, w = img.shape[0], img.shape[1]\n        for channel in range(2):\n            ws.append(w)\n            hs.append(h)\n            ids.append(f'{id}_{channel}')\n            string = rle_encode_one_mask(img[:,:,channel])\n            strings.append(string)\n    r = {\n        'ids': ids,\n        'strings': strings,\n    }\n    return r\n\n\nMASK_DIR_PATH = '/kaggle/working/prediction'\ndir = MASK_DIR_PATH\nres = mask2string(dir)\ndf = pd.DataFrame(columns=['Id', 'Expected'])\ndf['Id'] = res['ids']\ndf['Expected'] = res['strings']\n\ndf.to_csv(r'output.csv', index=False)\nprint('Done')","metadata":{"execution":{"iopub.status.busy":"2023-11-17T09:49:31.425435Z","iopub.status.idle":"2023-11-17T09:49:31.425902Z","shell.execute_reply.started":"2023-11-17T09:49:31.425660Z","shell.execute_reply":"2023-11-17T09:49:31.425684Z"},"trusted":true},"execution_count":null,"outputs":[]}]}